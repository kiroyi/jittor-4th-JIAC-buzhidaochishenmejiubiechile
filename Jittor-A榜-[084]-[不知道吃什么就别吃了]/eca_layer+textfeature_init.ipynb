{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abdb16fc-66c2-4e5b-8c71-340790e554e4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:36:25.156574Z",
     "iopub.status.busy": "2024-08-05T09:36:25.156101Z",
     "iopub.status.idle": "2024-08-05T09:38:33.385063Z",
     "shell.execute_reply": "2024-08-05T09:38:33.384201Z",
     "shell.execute_reply.started": "2024-08-05T09:36:25.156545Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i 0805 17:36:26.278341 92 lock.py:85] Create lock file:/root/.cache/jittor/jt1.3.9/g++11.4.0/py3.10.14/Linux-4.19.24-x10/IntelRXeonRPlaxf9/d731/jittor.lock\n",
      "[i 0805 17:36:26.286400 92 compiler.py:956] Jittor(1.3.9.5) src: /usr/local/lib/python3.10/site-packages/jittor\n",
      "[i 0805 17:36:26.288514 92 compiler.py:957] g++ at /usr/bin/g++(11.4.0)\n",
      "[i 0805 17:36:26.288587 92 compiler.py:958] cache_path: /root/.cache/jittor/jt1.3.9/g++11.4.0/py3.10.14/Linux-4.19.24-x10/IntelRXeonRPlaxf9/d731/default\n",
      "[i 0805 17:36:26.300494 92 __init__.py:412] Found nvcc(12.1.105) at /usr/local/cuda/bin/nvcc.\n",
      "[i 0805 17:36:26.485802 92 __init__.py:412] Found gdb(22.04.2) at /usr/bin/gdb.\n",
      "[i 0805 17:36:26.492218 92 __init__.py:412] Found addr2line(2.38) at /usr/bin/addr2line.\n",
      "[i 0805 17:36:26.909003 92 compiler.py:1011] cuda key:cu12.1.105_sm_70\n",
      "[i 0805 17:36:26.936283 92 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.9/g++11.4.0/py3.10.14/Linux-4.19.24-x10/IntelRXeonRPlaxf9/d731/default/cu12.1.105_sm_70\n",
      "[i 0805 17:36:26.936448 92 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.9/g++11.4.0/py3.10.14/Linux-4.19.24-x10/IntelRXeonRPlaxf9/d731/default/cu12.1.105_sm_70/jit\n",
      "[i 0805 17:36:26.936542 92 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.9/g++11.4.0/py3.10.14/Linux-4.19.24-x10/IntelRXeonRPlaxf9/d731/default/cu12.1.105_sm_70/obj_files\n",
      "[i 0805 17:36:26.936624 92 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.9/g++11.4.0/py3.10.14/Linux-4.19.24-x10/IntelRXeonRPlaxf9/d731/default/cu12.1.105_sm_70/gen\n",
      "[i 0805 17:36:26.936713 92 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.9/g++11.4.0/py3.10.14/Linux-4.19.24-x10/IntelRXeonRPlaxf9/d731/default/cu12.1.105_sm_70/tmp\n",
      "[i 0805 17:36:26.936792 92 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.9/g++11.4.0/py3.10.14/Linux-4.19.24-x10/IntelRXeonRPlaxf9/d731/default/cu12.1.105_sm_70/checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0805 17:36:33.827751 80 log.cc:351] Load log_sync: 1\u001b[m\n",
      "\u001b[38;5;2m[i 0805 17:36:49.100478 80 __init__.py:227] Total mem: 31.41GB, using 10 procs for compiling.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling jittor_core(150/151) used: 59.383s eta: 0.396ss\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0805 17:37:49.221617 80 log.cc:351] Load log_sync: 1\u001b[m\n",
      "\u001b[38;5;2m[i 0805 17:37:49.222705 80 jit_compiler.cc:28] Load cc_path: /usr/bin/g++\u001b[m\n",
      "\u001b[38;5;2m[i 0805 17:37:49.351494 80 init.cc:63] Found cuda archs: [70,]\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling jittor_core(151/151) used: 59.729s eta: 0.000s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0805 17:37:51.972347 80 __init__.py:412] Found mpicc(4.1.2) at /usr/bin/mpicc.\u001b[m\n",
      "\u001b[38;5;2m[i 0805 17:37:51.986403 80 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.9/g++11.4.0/py3.10.14/Linux-4.19.24-x10/IntelRXeonRPlaxf9/d731/default/cu12.1.105_sm_70/custom_ops\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling jittor_mpi_core(6/7) used: 2.367s eta: 0.394s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0805 17:37:54.619926 80 compile_extern.py:378] Downloading cutt...\u001b[m\n",
      "\u001b[38;5;2m[i 0805 17:37:54.631207 80 compile_extern.py:391] installing cutt...\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling jittor_mpi_core(7/7) used: 2.524s eta: 0.000s\n",
      "Compiling libcutt(9/9) used: 12.856s eta: 0.000s\n",
      "Compiling gen_ops_mkl_test_mkl_conv_mkl_matmul_mkl_conv_back___hashcad247(6/7) used: 3.567s eta: 0.595s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0805 17:38:13.332327 80 compiler.py:34] Create cache dir: /root/.cache/jittor/jt1.3.9/g++11.4.0/py3.10.14/Linux-4.19.24-x10/IntelRXeonRPlaxf9/d731/default/cu12.1.105_sm_70/cuda\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling gen_ops_mkl_test_mkl_conv_mkl_matmul_mkl_conv_back___hashcad247(7/7) used: 3.839s eta: 0.000s\n",
      "Compiling gen_ops_cub_test_cub_cumsum_cub_argsort_cub_where____hash4eb589(6/6) used: 3.039s eta: 0.000s\n",
      "Compiling gen_ops_cublas_test_cublas_acc_matmul_cublas_matmu___hash02a226(8/8) used: 2.529s eta: 0.000s\n",
      "Compiling gen_ops_cudnn_conv_backward_w_cudnn_conv3d_backwar___hash25ad86(16/16) used: 6.876s eta: 0.000s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import jittor as jt\n",
    "import jittor.nn as nn\n",
    "import jittor.optim as optim\n",
    "from jittor.dataset import Dataset\n",
    "from jittor.dataset import DataLoader\n",
    "from jittor import transform\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import jclip as clip\n",
    "\n",
    "train_label = pd.read_csv('/mnt/workspace/JCLIP/Dataset/train_1234.txt')\n",
    "val_label = pd.read_csv('/mnt/workspace/JCLIP/Dataset/valid.txt')\n",
    "test_label = pd.read_csv('/mnt/workspace/JCLIP/Dataset/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abfc0100-e568-4c3f-a2ec-0a3b91bd3d96",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:38:33.387203Z",
     "iopub.status.busy": "2024-08-05T09:38:33.386773Z",
     "iopub.status.idle": "2024-08-05T09:38:33.397480Z",
     "shell.execute_reply": "2024-08-05T09:38:33.396813Z",
     "shell.execute_reply.started": "2024-08-05T09:38:33.387175Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_label['path'] = '/mnt/workspace/JCLIP/Dataset/' + train_label['img_name']\n",
    "val_label['path'] = '/mnt/workspace/JCLIP/Dataset/' + val_label['img_name']\n",
    "test_label['path'] = '/mnt/workspace/JCLIP/Dataset/TestSetA/' + test_label['img_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "056026dd-0f4c-495b-b39d-83a9f031588c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:39:15.206546Z",
     "iopub.status.busy": "2024-08-05T09:39:15.206060Z",
     "iopub.status.idle": "2024-08-05T09:39:15.224226Z",
     "shell.execute_reply": "2024-08-05T09:39:15.223584Z",
     "shell.execute_reply.started": "2024-08-05T09:39:15.206518Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>target</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TrainSet/Animal/Bear/5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/mnt/workspace/JCLIP/Dataset/TrainSet/Animal/B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrainSet/Animal/Bear/6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/mnt/workspace/JCLIP/Dataset/TrainSet/Animal/B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TrainSet/Animal/Bear/7.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/mnt/workspace/JCLIP/Dataset/TrainSet/Animal/B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TrainSet/Animal/Bear/8.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/mnt/workspace/JCLIP/Dataset/TrainSet/Animal/B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TrainSet/Animal/Bear/9.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/mnt/workspace/JCLIP/Dataset/TrainSet/Animal/B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>TrainSet/Thu-dog/papillon/10.jpg</td>\n",
       "      <td>373</td>\n",
       "      <td>/mnt/workspace/JCLIP/Dataset/TrainSet/Thu-dog/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>TrainSet/Thu-dog/papillon/11.jpg</td>\n",
       "      <td>373</td>\n",
       "      <td>/mnt/workspace/JCLIP/Dataset/TrainSet/Thu-dog/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>TrainSet/Thu-dog/papillon/12.jpg</td>\n",
       "      <td>373</td>\n",
       "      <td>/mnt/workspace/JCLIP/Dataset/TrainSet/Thu-dog/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>TrainSet/Thu-dog/papillon/13.jpg</td>\n",
       "      <td>373</td>\n",
       "      <td>/mnt/workspace/JCLIP/Dataset/TrainSet/Thu-dog/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>TrainSet/Thu-dog/papillon/14.jpeg</td>\n",
       "      <td>373</td>\n",
       "      <td>/mnt/workspace/JCLIP/Dataset/TrainSet/Thu-dog/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3740 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               img_name  target  \\\n",
       "0            TrainSet/Animal/Bear/5.jpg       0   \n",
       "1            TrainSet/Animal/Bear/6.jpg       0   \n",
       "2            TrainSet/Animal/Bear/7.jpg       0   \n",
       "3            TrainSet/Animal/Bear/8.jpg       0   \n",
       "4            TrainSet/Animal/Bear/9.jpg       0   \n",
       "...                                 ...     ...   \n",
       "3735   TrainSet/Thu-dog/papillon/10.jpg     373   \n",
       "3736   TrainSet/Thu-dog/papillon/11.jpg     373   \n",
       "3737   TrainSet/Thu-dog/papillon/12.jpg     373   \n",
       "3738   TrainSet/Thu-dog/papillon/13.jpg     373   \n",
       "3739  TrainSet/Thu-dog/papillon/14.jpeg     373   \n",
       "\n",
       "                                                   path  \n",
       "0     /mnt/workspace/JCLIP/Dataset/TrainSet/Animal/B...  \n",
       "1     /mnt/workspace/JCLIP/Dataset/TrainSet/Animal/B...  \n",
       "2     /mnt/workspace/JCLIP/Dataset/TrainSet/Animal/B...  \n",
       "3     /mnt/workspace/JCLIP/Dataset/TrainSet/Animal/B...  \n",
       "4     /mnt/workspace/JCLIP/Dataset/TrainSet/Animal/B...  \n",
       "...                                                 ...  \n",
       "3735  /mnt/workspace/JCLIP/Dataset/TrainSet/Thu-dog/...  \n",
       "3736  /mnt/workspace/JCLIP/Dataset/TrainSet/Thu-dog/...  \n",
       "3737  /mnt/workspace/JCLIP/Dataset/TrainSet/Thu-dog/...  \n",
       "3738  /mnt/workspace/JCLIP/Dataset/TrainSet/Thu-dog/...  \n",
       "3739  /mnt/workspace/JCLIP/Dataset/TrainSet/Thu-dog/...  \n",
       "\n",
       "[3740 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4750b9-98dc-4153-9034-77672a97aaf2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:39:15.714818Z",
     "iopub.status.busy": "2024-08-05T09:39:15.714328Z",
     "iopub.status.idle": "2024-08-05T09:39:15.719768Z",
     "shell.execute_reply": "2024-08-05T09:39:15.719040Z",
     "shell.execute_reply.started": "2024-08-05T09:39:15.714789Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image_855.jpeg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label['img_name'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdefeaea-0fdf-4347-ba09-6854d701cb68",
   "metadata": {},
   "source": [
    "# 模型训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5fa4a18-794d-456e-8867-7077deee89bb",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:45:00.794222Z",
     "iopub.status.busy": "2024-08-05T09:45:00.793717Z",
     "iopub.status.idle": "2024-08-05T09:45:00.802534Z",
     "shell.execute_reply": "2024-08-05T09:45:00.801682Z",
     "shell.execute_reply.started": "2024-08-05T09:45:00.794190Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, *meters):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = \"\"\n",
    "\n",
    "    def pr2int(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2591ef1-98d1-49dc-bd81-409fe28b6132",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:45:01.317747Z",
     "iopub.status.busy": "2024-08-05T09:45:01.317161Z",
     "iopub.status.idle": "2024-08-05T09:45:01.335937Z",
     "shell.execute_reply": "2024-08-05T09:45:01.335192Z",
     "shell.execute_reply.started": "2024-08-05T09:45:01.317713Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, bs_value):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    batch_num = int(len(val_loader) / bs_value)\n",
    "    progress = ProgressMeter(batch_num, batch_time, losses, top1)\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    # 加载clip\n",
    "    model_clip, preprocess = clip.load(\"/mnt/workspace/JCLIP/ViT-B-32.pkl\")\n",
    "\n",
    "    with jt.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (imgs, target) in tqdm(enumerate(val_loader), total=batch_num):\n",
    "            # 将 NumPy 数组转换为 PIL 图像并进行预处理\n",
    "            images = [Image.fromarray(img_np) for img_np in imgs.numpy()]\n",
    "\n",
    "            # 预处理图像\n",
    "            images_preprocessed = jt.cat([preprocess(image).unsqueeze(0) for image in images], dim=0)\n",
    "            images_preprocessed = jt.misc.to(images_preprocessed, 'cuda')\n",
    "\n",
    "            images_clip_features = model_clip.encode_image(images_preprocessed)\n",
    "            # [batch_size, 512]\n",
    "            images_clip_features /= images_clip_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            target = jt.misc.to(target, 'cuda')\n",
    "\n",
    "            # compute output\n",
    "            output = model(images_clip_features)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = (output.argmax(1)[0].view(-1) == target.float().view(-1)).float().mean() * 100\n",
    "\n",
    "            losses.update(loss.item(), imgs.size(0))\n",
    "            top1.update(acc, imgs.size(0))\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f}'\n",
    "              .format(top1=top1))\n",
    "        return top1\n",
    "\n",
    "\n",
    "def predict(test_label, model, tta=10):\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    # 加载clip\n",
    "    model_clip, preprocess = clip.load(\"/mnt/workspace/JCLIP/ViT-B-32.pkl\")\n",
    "\n",
    "    test_num = len(test_label)\n",
    "\n",
    "    test_pred_tta = None\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "        with jt.no_grad():\n",
    "            end = time.time()\n",
    "            for i in tqdm(range(test_num), total=test_num):\n",
    "\n",
    "                img_path = test_label['path'][i]\n",
    "                image = Image.open(img_path)\n",
    "                image = preprocess(image).unsqueeze(0)\n",
    "\n",
    "                image_features = model_clip.encode_image(image)\n",
    "                image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "                # compute output\n",
    "                output = model(image_features)\n",
    "\n",
    "                output = nn.softmax(output, dim=1)\n",
    "                output = output.numpy()\n",
    "\n",
    "                test_pred.append(output)\n",
    "        test_pred = np.vstack(test_pred)\n",
    "\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "\n",
    "    return test_pred_tta\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, bs_value):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "\n",
    "    # jittor的len(train_loader)不会随着batch_size的变化而改变\n",
    "    # 永远都是1496\n",
    "    batch_num = int(len(train_loader) / bs_value)\n",
    "    progress = ProgressMeter(batch_num, batch_time, losses, top1)\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    # 加载clip\n",
    "    model_clip, preprocess = clip.load(\"/mnt/workspace/JCLIP/ViT-B-32.pkl\")\n",
    "    model_clip.cuda()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (imgs, target) in enumerate(train_loader):\n",
    "        # img [1, 224, 224, 3]  但是用不着\n",
    "\n",
    "        # 将 NumPy 数组转换为 PIL 图像并进行预处理\n",
    "        images = [Image.fromarray(img_np) for img_np in imgs.numpy()]\n",
    "\n",
    "\n",
    "        # 预处理图像\n",
    "        images_preprocessed = jt.cat([preprocess(image).unsqueeze(0) for image in images], dim=0)\n",
    "        images_preprocessed = jt.misc.to(images_preprocessed, 'cuda')\n",
    "\n",
    "        images_clip_features = model_clip.encode_image(images_preprocessed)\n",
    "        # [batch_size, 512]\n",
    "        images_clip_features /= images_clip_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        target = jt.misc.to(target, 'cuda')\n",
    "\n",
    "        # compute output\n",
    "        output = model(images_clip_features)\n",
    "        # output [batch_size, 374] target[batch_size]\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.item(), imgs.size(0))\n",
    "\n",
    "        # print(f'tput.argmax(1)：{output.argmax(1)}')\n",
    "        # print(f'tput.argmax(1)[0]的shape：{output.argmax(1)[0].shape}')\n",
    "        # tput.argmax(1)：(jt.Var([351 351 285 131], dtype=int32), jt.Var([0.0555831  0.0470255  0.04495085 0.04521766], dtype=float32))\n",
    "        # 所以要改为output.argmax(1)[0]\n",
    "        acc = (output.argmax(1)[0].view(-1) == target.float().view(-1)).float().mean() * 100\n",
    "        top1.update(acc, n=imgs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.backward(loss)\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 4 == 0:\n",
    "            progress.pr2int(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407b41f1-5c41-41cd-9456-c541e04f8b4f",
   "metadata": {},
   "source": [
    "# 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ac86908-20d1-4117-ba3a-d5ffa56c19d8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:45:02.799563Z",
     "iopub.status.busy": "2024-08-05T09:45:02.799060Z",
     "iopub.status.idle": "2024-08-05T09:45:02.805569Z",
     "shell.execute_reply": "2024-08-05T09:45:02.804832Z",
     "shell.execute_reply.started": "2024-08-05T09:45:02.799534Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFDIDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        super().__init__()\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label\n",
    "\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "        label = self.img_label[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        # jt.array(np.array(self.img_label[index]), dtype=np.float32)\n",
    "#         label = jt.array(np.array(self.img_label[index]), dtype=np.float32)\n",
    "\n",
    "#         print(f'label处理前{self.img_label[index]}')\n",
    "#         print(f'label处理后{label}')\n",
    "#         print(f'img类型 和 形状：{img.dtype} {img.shape}')\n",
    "#         print(f'label类型 和 形状：{label.dtype} {label.shape}')\n",
    "\n",
    "        # 返回必须为图片和int，不要去变成tensor\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a0bee2-fb3a-4ff5-9bab-0fc8f7b3dc8c",
   "metadata": {},
   "source": [
    "# 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b08178-28d1-49c0-9e6c-556bab6ad329",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:48:48.463248Z",
     "iopub.status.busy": "2024-08-05T09:48:48.462732Z",
     "iopub.status.idle": "2024-08-05T09:48:48.468982Z",
     "shell.execute_reply": "2024-08-05T09:48:48.468122Z",
     "shell.execute_reply.started": "2024-08-05T09:48:48.463216Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class eca_layer(nn.Module):\n",
    "    def __init__(self, channels, k_size=3):\n",
    "        super(eca_layer).__init__()\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def execute(self, x):\n",
    "\n",
    "        original_x = x\n",
    "        # Two different branches of ECA module\n",
    "        x = self.conv(x.unsqueeze(-1).transpose(-1, -2)).transpose(-1, -2).squeeze(-1)\n",
    "        # Multi-scale information fusion\n",
    "        x = self.sigmoid(x)\n",
    "        return original_x * x\n",
    "\n",
    "class attention_classifier(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, textfeatures_weights):\n",
    "        super(attention_classifier).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=in_channels, out_features=out_channels, bias=False)\n",
    "        self.eca_layer = eca_layer(in_channels)\n",
    "        self.init_weights(textfeatures_weights)\n",
    "\n",
    "    def init_weights(self, textfeatures_weights):\n",
    "        # 初始化权重\n",
    "        self.fc1.weight = jt.array(textfeatures_weights)\n",
    "\n",
    "    def execute(self, x):\n",
    "\n",
    "        # 通道注意力\n",
    "        x = self.eca_layer(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# class attention_classifier(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(attention_classifier).__init__()\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(in_channels, 768, bias=False),\n",
    "#             nn.BatchNorm1d(768),\n",
    "#             nn.ReLU(),\n",
    "\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(768, out_channels, bias=False),\n",
    "#         )\n",
    "\n",
    "#     def execute(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da936de2-a2b9-4838-905e-1a31ab29b5da",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:48:55.816277Z",
     "iopub.status.busy": "2024-08-05T09:48:55.815775Z",
     "iopub.status.idle": "2024-08-05T09:48:55.826042Z",
     "shell.execute_reply": "2024-08-05T09:48:55.825072Z",
     "shell.execute_reply.started": "2024-08-05T09:48:55.816245Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_textfeatures():\n",
    "    # 加载clip\n",
    "    model_clip, preprocess = clip.load(\"/mnt/workspace/JCLIP/models_pkl/clip_ft/clip_ft_Epoch47_100.0.pkl\")\n",
    "    model_clip.cuda()\n",
    "\n",
    "\n",
    "    classes = open('/mnt/workspace/JCLIP/Dataset/classes.txt').read().splitlines()\n",
    "    # remove the prefix Animal, Thu-dog, Caltech-101, Food-101\n",
    "\n",
    "    new_classes1 = []\n",
    "    new_classes2 = []\n",
    "    for c in classes:\n",
    "        c = c.split(' ')[0]\n",
    "        if c.startswith('Animal'):\n",
    "            c = c[7:]\n",
    "            c1 = 'A photo of ' + c.lower().replace('_', ' ') + ', a type of animal'\n",
    "            c2 = 'A photo animal of ' + c.lower().replace('_', ' ') #+ '.'\n",
    "        if c.startswith('Thu-dog'):\n",
    "            c = c[8:]\n",
    "            c1 = 'A photo of ' + c.lower().replace('_', ' ') + ', a type of dog'\n",
    "            c2 = 'A photo dog of ' + c.lower().replace('_', ' ') #+ '.'\n",
    "        if c.startswith('Caltech-101'):\n",
    "            c = c[12:]\n",
    "            c1 = 'A photo of ' + c.lower().replace('_', ' ')\n",
    "            c2 = 'A photo of ' + c.lower().replace('_', ' ') #+ '.'\n",
    "        if c.startswith('Food-101'):\n",
    "            c = c[9:]\n",
    "            c1 = 'A photo of ' + c.lower().replace('_', ' ') + ', a type of food'\n",
    "            c2 = 'A photo food of ' + c.lower().replace('_', ' ') #+ '.'\n",
    "        new_classes1.append(c1)\n",
    "        new_classes2.append(c2)\n",
    "\n",
    "    text1 = clip.tokenize(new_classes1)\n",
    "    text2 = clip.tokenize(new_classes2)\n",
    "\n",
    "\n",
    "    text_features1 = model_clip.encode_text(text1)\n",
    "    text_features1 /= text_features1.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    text_features2 = model_clip.encode_text(text2)\n",
    "    text_features2 /= text_features2.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    text_features = (text_features1 + text_features2) / 2.\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    return text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4da22dcc-aba9-4990-800b-8c002d1b4a83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T09:49:00.906555Z",
     "iopub.status.busy": "2024-08-05T09:49:00.906072Z",
     "iopub.status.idle": "2024-08-05T09:49:11.895015Z",
     "shell.execute_reply": "2024-08-05T09:49:11.894273Z",
     "shell.execute_reply.started": "2024-08-05T09:49:00.906524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[i 0805 17:49:11.800391 80 cuda_flags.cc:49] CUDA enabled.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "text_features = process_textfeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec70c6-4497-45d1-90c9-50600c4b0eea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d537bfde-f01e-42ef-b390-63f92d5e9b07",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:49:27.167447Z",
     "iopub.status.busy": "2024-08-05T09:49:27.166955Z",
     "iopub.status.idle": "2024-08-05T09:49:27.171554Z",
     "shell.execute_reply": "2024-08-05T09:49:27.170468Z",
     "shell.execute_reply.started": "2024-08-05T09:49:27.167416Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameter\n",
    "epoch_num = 1\n",
    "bs_value = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dab4aad-e739-4f93-995c-ebc8828953ea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:49:20.316807Z",
     "iopub.status.busy": "2024-08-05T09:49:20.316324Z",
     "iopub.status.idle": "2024-08-05T09:49:20.322087Z",
     "shell.execute_reply": "2024-08-05T09:49:20.321414Z",
     "shell.execute_reply.started": "2024-08-05T09:49:20.316778Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用hugging face预训练模型\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../models_pkl/model_linear/model+compress_Epoch.pkl\"\n",
    "\n",
    "model = attention_classifier(in_channels=512, out_channels=374, textfeatures_weights=text_features)\n",
    "\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(jt.load(model_path))\n",
    "    print(\"使用以往的模型继续训练\")\n",
    "else:\n",
    "    print(\"使用hugging face预训练模型\")\n",
    "\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d83069c0-2d4a-4a77-b96d-557c553b43b6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-05T09:49:29.344383Z",
     "iopub.status.busy": "2024-08-05T09:49:29.343871Z",
     "iopub.status.idle": "2024-08-05T09:49:29.350920Z",
     "shell.execute_reply": "2024-08-05T09:49:29.350163Z",
     "shell.execute_reply.started": "2024-08-05T09:49:29.344352Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_trans = transform.Compose([\n",
    "                transform.Resize((224, 224)),\n",
    "                transform.RandomRotation(degrees=180),\n",
    "                transform.ColorJitter(0.5),\n",
    "                transform.RandomHorizontalFlip(),\n",
    "                transform.RandomVerticalFlip(),\n",
    "                # transform.ToTensor(),\n",
    "                # transform.ImageNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "val_trans = transform.Compose([\n",
    "                transform.Resize((224, 224)),\n",
    "                # transform.ToTensor(),\n",
    "                # transform.ImageNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "train_dataset = FFDIDataset(train_label['path'], train_label['target'], train_trans).set_attrs(batch_size=bs_value, shuffle=True)\n",
    "val_dataset = FFDIDataset(val_label['path'], val_label['target'], val_trans).set_attrs(batch_size=bs_value, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset)\n",
    "val_loader = DataLoader(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c7d1d66-1995-4ed1-9bf7-0423e93e0bc4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:24:14.732035Z",
     "iopub.status.busy": "2024-07-29T08:24:14.731549Z",
     "iopub.status.idle": "2024-07-29T08:24:14.735998Z",
     "shell.execute_reply": "2024-07-29T08:24:14.735220Z",
     "shell.execute_reply.started": "2024-07-29T08:24:14.732002Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(train_loader)\n",
    "# print(len(train_loader))\n",
    "# for i, (img, target) in enumerate(train_loader):\n",
    "#     # img_array = img.numpy()\n",
    "#     # print(img_array.shape)\n",
    "#     # images_features = process_images_to_features(img_array)\n",
    "#     # print(images_features.shape)\n",
    "#     # print(type(images_features))\n",
    "#     # print(target.shape)\n",
    "#     # print(type(target))\n",
    "#     if i == 0:\n",
    "#         print(type(img))\n",
    "#         # print(img.transpose((0, 3, 1, 2)).shape)\n",
    "#         print(type(target))\n",
    "#         img_arr = img.numpy()[0]\n",
    "#         print(img_arr.shape)\n",
    "#         img = Image.fromarray(img_arr)\n",
    "#         plt.imshow(img)\n",
    "#         plt.axis('off')  # 不显示坐标轴\n",
    "#         plt.show()\n",
    "#         img_path = train_label['path'][i]\n",
    "#         image = Image.open(img_path)\n",
    "#         plt.imshow(image)\n",
    "#         plt.axis('off')  # 不显示坐标轴\n",
    "#         plt.show()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ecca930-d3e0-4de9-aec6-4534d2137054",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-29T08:24:15.471400Z",
     "iopub.status.busy": "2024-07-29T08:24:15.470911Z",
     "iopub.status.idle": "2024-07-29T08:24:15.475612Z",
     "shell.execute_reply": "2024-07-29T08:24:15.474765Z",
     "shell.execute_reply.started": "2024-07-29T08:24:15.471369Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print(1e-3)\n",
    "#, weight_decay=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a50da6-3768-42de-aa72-3b8bda8e4f10",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.AdamW(model.parameters(), 0.005)\n",
    "scheduler = jt.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.85)\n",
    "best_acc = 0.0\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(epoch_num):\n",
    "    # scheduler.step()\n",
    "    print('Epoch: ', epoch)\n",
    "\n",
    "    # train(train_loader, model, criterion, optimizer, epoch, bs_value)\n",
    "    val_acc = validate(val_loader, model, criterion, bs_value)\n",
    "    # if train_acc.avg.item() > best_acc:\n",
    "    best_acc = round(val_acc.avg.item(), 2)\n",
    "    acc_list.append(best_acc)\n",
    "    model.save(f'../models_pkl/eca_layer+textfeature/model_Epoch{epoch}_{best_acc}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "41ac2e98-98e6-4251-a024-5ffe2eb568ce",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-23T15:32:03.848823Z",
     "iopub.status.busy": "2024-07-23T15:32:03.848306Z",
     "iopub.status.idle": "2024-07-23T15:35:12.100544Z",
     "shell.execute_reply": "2024-07-23T15:35:12.099674Z",
     "shell.execute_reply.started": "2024-07-23T15:32:03.848790Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用以往的模型继续训练\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3073/3073 [03:06<00:00, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3073, 374)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./model_ECA_bs4/model_Epoch49_100.0.pkl\"\n",
    "\n",
    "model = attention_classifier(in_channels=512, out_channels=374)\n",
    "\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(jt.load(model_path))\n",
    "    print(\"使用以往的模型继续训练\")\n",
    "else:\n",
    "    print(\"使用hugging face预训练模型\")\n",
    "\n",
    "\n",
    "\n",
    "test_pred = predict(test_label, model, 1)\n",
    "print(test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41745b56-3bec-405a-b00a-343577d41f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-25T12:24:39.010566Z",
     "iopub.status.busy": "2024-07-25T12:24:39.010025Z",
     "iopub.status.idle": "2024-07-25T12:27:53.694454Z",
     "shell.execute_reply": "2024-07-25T12:27:53.693711Z",
     "shell.execute_reply.started": "2024-07-25T12:24:39.010532Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3073/3073 [03:12<00:00, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3073, 374)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = predict(test_label, model, 1)\n",
    "print(test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c086fb1-c156-477f-8b34-2073b335ab9a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-25T12:28:25.440592Z",
     "iopub.status.busy": "2024-07-25T12:28:25.439836Z",
     "iopub.status.idle": "2024-07-25T12:28:25.467030Z",
     "shell.execute_reply": "2024-07-25T12:28:25.466278Z",
     "shell.execute_reply.started": "2024-07-25T12:28:25.440557Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_k = 5\n",
    "top_k_indices = np.argsort(test_pred, axis=1)[:, -top_k:]\n",
    "top_k_indices = np.flip(top_k_indices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09b1c61d-1442-47e8-811a-9d64aeefdc0e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-25T12:28:26.958322Z",
     "iopub.status.busy": "2024-07-25T12:28:26.957488Z",
     "iopub.status.idle": "2024-07-25T12:28:26.964822Z",
     "shell.execute_reply": "2024-07-25T12:28:26.964056Z",
     "shell.execute_reply.started": "2024-07-25T12:28:26.958280Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_label[['Top1', 'Top2', 'Top3', 'Top4', 'Top5']] = top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c818da4-b8e5-4a26-8600-cea38a4fb628",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_label[70: 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e298a8dc-35a7-43d1-859b-362280162b82",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-07-25T13:33:52.008873Z",
     "iopub.status.busy": "2024-07-25T13:33:52.008020Z",
     "iopub.status.idle": "2024-07-25T13:33:52.023373Z",
     "shell.execute_reply": "2024-07-25T13:33:52.022658Z",
     "shell.execute_reply.started": "2024-07-25T13:33:52.008838Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_save = ['img_name', 'Top1', 'Top2', 'Top3', 'Top4', 'Top5']\n",
    "df_selected = test_label[columns_to_save]\n",
    "df_selected.to_csv('./model_output/result.txt', sep=' ', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
